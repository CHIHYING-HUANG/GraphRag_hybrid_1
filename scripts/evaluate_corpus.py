#!/usr/bin/env python3
"""
ç¨ç«‹ Corpus è©•ä¼°è…³æœ¬

ä½¿ç”¨æ–¹å¼ï¼š
    python evaluate_corpus.py --limit 5  # è©•ä¼° 5 é¡Œ
    python evaluate_corpus.py --limit 50  # è©•ä¼°å…¨éƒ¨ 50 é¡Œ
    python evaluate_corpus.py --limit 5 --k 3  # è©•ä¼° 5 é¡Œï¼ŒTop-3 æª¢ç´¢
"""

import asyncio
import argparse
import json
import sys
from pathlib import Path

# å°‡å°ˆæ¡ˆæ ¹ç›®éŒ„åŠ å…¥ Python è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.services.service_layer import corpus_evaluation_service


def print_results(results: dict):
    """
    æ ¼å¼åŒ–è¼¸å‡ºè©•ä¼°çµæœ
    
    åƒæ•¸ï¼š
        results (dict): è©•ä¼°çµæœå­—å…¸
    """
    print("\n" + "="*80)
    print("ğŸ“Š Corpus è©•ä¼°çµæœ")
    print("="*80)
    
    # æ•´é«”æŒ‡æ¨™
    overall = results["overall"]
    print("\nã€æ•´é«”æŒ‡æ¨™ã€‘")
    print(f"  ç¸½å•é¡Œæ•¸:           {overall['total_questions']}")
    print(f"  Hit Rate (å–®ä¸€):    {overall['hit_rate']:.2%}")
    print(f"  Partial Hit Rate:   {overall['partial_hit_rate']:.2%}")
    print(f"  MRR:                {overall['mrr']:.4f}")
    print(f"  ç”Ÿæˆé€šéç‡:         {overall['generation_pass_rate']:.2%}")
    
    # æŒ‰è³‡æ–™ä¾†æºåˆ†çµ„
    print("\nã€æŒ‰è³‡æ–™ä¾†æºåˆ†çµ„ã€‘")
    print()
    
    by_source = results["by_source"]
    for source_name in ["drcd", "hotpotqa", "2wiki"]:
        if source_name not in by_source:
            continue
        
        source = by_source[source_name]
        print(f"ã€{source_name.upper()}ã€‘")
        print(f"  å•é¡Œæ•¸:             {source['total_questions']}")
        print(f"  Hit Rate (å–®ä¸€):    {source['hit_rate']:.2%}")
        print(f"  Partial Hit Rate:   {source['partial_hit_rate']:.2%}")
        print(f"  MRR:                {source['mrr']:.4f}")
        print(f"  ç”Ÿæˆé€šéç‡:         {source['generation_pass_rate']:.2%}")
        print()
    
    print("="*80)


async def main():
    """
    ä¸»ç¨‹å¼
    """
    # è§£æå‘½ä»¤åˆ—åƒæ•¸
    parser = argparse.ArgumentParser(description="åŸ·è¡Œ Corpus è©•ä¼°")
    parser.add_argument(
        "--limit", 
        type=int, 
        default=5,
        help="è¦è©•ä¼°çš„å•é¡Œæ•¸é‡ï¼ˆé è¨­ 5ï¼‰"
    )
    parser.add_argument(
        "--k", 
        type=int, 
        default=5,
        help="Top-K æª¢ç´¢æ•¸é‡ï¼ˆé è¨­ 5ï¼‰"
    )
    parser.add_argument(
        "--queries", 
        type=str, 
        default="data/queries.json",
        help="queries.json çš„è·¯å¾‘ï¼ˆé è¨­ queries.jsonï¼‰"
    )
    parser.add_argument(
        "--output", 
        type=str, 
        default=None,
        help="å°‡çµæœå„²å­˜åˆ° JSON æª”æ¡ˆï¼ˆé¸å¡«ï¼‰"
    )
    
    args = parser.parse_args()
    
    print(f"\nğŸš€ é–‹å§‹è©•ä¼°...")
    print(f"   å•é¡Œæ•¸é‡: {args.limit}")
    print(f"   æª¢ç´¢æ•¸é‡: Top-{args.k}")
    print(f"   è³‡æ–™ä¾†æº: {args.queries}")
    
    try:
        # åŸ·è¡Œè©•ä¼°
        results = await corpus_evaluation_service.run_evaluation(
            queries_path=args.queries,
            k=args.k,
            limit=args.limit
        )
        
        # è¼¸å‡ºçµæœ
        print_results(results)
        
        # å„²å­˜åˆ°æª”æ¡ˆï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if args.output:
            with open(args.output, "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"\nâœ… çµæœå·²å„²å­˜è‡³ï¼š{args.output}")
        
        print("\nâœ… è©•ä¼°å®Œæˆï¼")
        
    except FileNotFoundError as e:
        print(f"\nâŒ éŒ¯èª¤ï¼š{e}")
        print("\nè«‹ç¢ºä¿ï¼š")
        print("  1. corpus.json å­˜åœ¨æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„")
        print("  2. queries.json å­˜åœ¨æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„")
        print("  3. å·²åŸ·è¡Œ corpus è³‡æ–™åŒ¯å…¥")
        sys.exit(1)
        
    except Exception as e:
        print(f"\nâŒ è©•ä¼°å¤±æ•—ï¼š{e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
